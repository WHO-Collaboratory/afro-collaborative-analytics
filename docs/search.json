[
  {
    "objectID": "task9.html",
    "href": "task9.html",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "",
    "text": "This task covers forecasting cases and deaths. You will learn how to build forecasting models and generate predictions of future disease incidence, by accounting for incomplete observations using Bayesian methods in {EpiNow2}. Covers short-term projections assuming a constant value for the reproduction number based on its latest estimate, handling incomplete observations, and forecasting secondary outcomes based on primary observations."
  },
  {
    "objectID": "task9.html#overview",
    "href": "task9.html#overview",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "",
    "text": "This task covers forecasting cases and deaths. You will learn how to build forecasting models and generate predictions of future disease incidence, by accounting for incomplete observations using Bayesian methods in {EpiNow2}. Covers short-term projections assuming a constant value for the reproduction number based on its latest estimate, handling incomplete observations, and forecasting secondary outcomes based on primary observations."
  },
  {
    "objectID": "task9.html#learning-objectives",
    "href": "task9.html#learning-objectives",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nBuild forecasting models for epidemiological data\nGenerate short-term forecasts\nQuantify forecast uncertainty\nForecast secondary observations"
  },
  {
    "objectID": "task9.html#tutorial",
    "href": "task9.html#tutorial",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task9.html#downloading-forecast-estimates",
    "href": "task9.html#downloading-forecast-estimates",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "Downloading Forecast Estimates",
    "text": "Downloading Forecast Estimates\nNote: Running EpiNow2 can be computationally expensive and may take several minutes to complete. If you want to skip this step, you can download the pre-computed estimates file and place it in your outputs/ folder:\nDownload nowcast estimates"
  },
  {
    "objectID": "task9.html#example-report",
    "href": "task9.html#example-report",
    "title": "Task 9: Forecasting cases and deaths",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\nForecasting incidence with incomplete observations\nWe first used {EpiNow2} to forecast incidence of Ebola, accounting for under-reporting of outbreak cases. We estimate that only 40% of actual cases were reported during surveillance activities.\n\n\nCode\n# INSTALL AND LOAD PACKAGES\npacman::p_load(tidyverse, EpiNow2, incidence2, reactable, rio)\n\n# LOAD DATA\n# Import linelist data and convert to incidence\nebola_incidence &lt;- readRDS(\"data/linelist.rds\") |&gt;\n  incidence2::incidence(\n    date_index = \"date_onset\",\n    count_values_to = \"confirm\",\n    date_names_to = \"date\",\n    complete_dates = TRUE\n  ) |&gt;\n  dplyr::select(-count_variable)\n\n# Defining generation time and Rt priors\n# Generation time\ngeneration_time_fixed &lt;- EpiNow2::LogNormal(\n  mean = 4,\n  sd = 2,\n  max = 15\n)\n\n# define Rt prior distribution\nrt_prior &lt;- EpiNow2::rt_opts(prior = EpiNow2::LogNormal(mean = 2, sd = 2))\n\n# Define observation model with 40% of cases being reported\nobs_scale &lt;- EpiNow2::Normal(mean = 0.4, sd = 0.01)\n\n# Check if the analysis has been run before and run EpiNow2 if not\nfile_name &lt;- \"outputs/forecast_estimates.rds\"\nif (file.exists(file_name)) {\n  forecast_estimates &lt;- import(file_name)\n} else {\n  # forecasting with epinow ---------------------------------------------------\n  withr::local_options(base::list(mc.cores = 4))\n  forecast_estimates &lt;- EpiNow2::epinow(\n    data = ebola_incidence,\n    generation_time = EpiNow2::generation_time_opts(generation_time_fixed),\n    rt = rt_prior,\n    # Add observation model\n    obs = EpiNow2::obs_opts(scale = obs_scale),\n    # Forecast window\n    forecast = forecast_opts(horizon = 15),\n    stan = EpiNow2::stan_opts(samples = 500, chains = 2)\n  )\n  export(forecast_estimates, file_name)\n}\n\nforecast_estimates$plots$infections\n\n\n\n\n\n\n\n\n\n\n\nForecasting secondary observations\n\n\nCode\n# Select early stages of the outbreak and convert data to EpiNow2 input, with\n# date, primary, and secondary columns\n\nebola_cases_deaths &lt;- readRDS(\"data/linelist.rds\") |&gt;\n  # Create date_death column: use date_outcome for entries where outcome == \"Death\"\n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, as.Date(NA))) |&gt;\n  incidence2::incidence(\n    date_index = c(\"date_onset\", \"date_death\"),\n    date_names_to = \"date\",\n    complete_dates = TRUE\n  ) |&gt;\n  pivot_wider(names_from = count_variable, values_from = count) |&gt;\n  rename(primary = date_onset, secondary = date_death)\n\n# onset to death delay ---------------------------------------------------------\nonset_death_ebola &lt;- epiparameter::epiparameter_db(\n  disease = \"ebola\",\n  epi_name = \"onset to death\",\n  single_epiparameter = TRUE\n)\n\nonset_death_ebola_discrete &lt;- epiparameter::discretise(onset_death_ebola)\n\nod_ebola_EN2 &lt;-\n  EpiNow2::Gamma(\n    mean = onset_death_ebola$summary_stats$mean,\n    sd = onset_death_ebola$summary_stats$sd,\n    max = quantile(onset_death_ebola, p = 0.99)\n  )\n\n# Establish relationship between cases and deaths\ndata_od_estimation &lt;- ebola_cases_deaths |&gt; slice(20:150)\nestimate_cases_to_deaths &lt;- EpiNow2::estimate_secondary(\n  data = data_od_estimation,\n  secondary = EpiNow2::secondary_opts(type = \"incidence\"),\n  delays = EpiNow2::delay_opts(od_ebola_EN2)\n)\n\n\nWe then forecasted the number of deaths that would arise from reported Ebola cases in the early stages of the outbreak that started in 2014.\n\n\nCode\nplot(estimate_cases_to_deaths, primary = TRUE)\n\n\n\n\n\n\n\n\n\nCode\n# Forecast from day 151 to day 300 (not included in model fit)\n# Rename primary to value (required by forecast_secondary)\ncases_to_forecast &lt;- ebola_cases_deaths |&gt;\n  slice(151:300) |&gt;\n  select(date, primary) |&gt;\n  rename(value = primary)\n\n# Forecast secondary cases\ndeaths_forecast &lt;- EpiNow2::forecast_secondary(\n  estimate = estimate_cases_to_deaths,\n  primary = cases_to_forecast\n)\n\nplot(deaths_forecast)"
  },
  {
    "objectID": "task7.html",
    "href": "task7.html",
    "title": "Task 7: Estimating the reproduction number",
    "section": "",
    "text": "This task covers estimating the basic and effective reproduction number (R0 and Rt), as well as other relevant metrics to quantify transmissibility such as the growth rate. You will learn methods for calculating these key epidemiological metrics from outbreak data, by accounting for reporting delays and uncertainty."
  },
  {
    "objectID": "task7.html#overview",
    "href": "task7.html#overview",
    "title": "Task 7: Estimating the reproduction number",
    "section": "",
    "text": "This task covers estimating the basic and effective reproduction number (R0 and Rt), as well as other relevant metrics to quantify transmissibility such as the growth rate. You will learn methods for calculating these key epidemiological metrics from outbreak data, by accounting for reporting delays and uncertainty."
  },
  {
    "objectID": "task7.html#learning-objectives",
    "href": "task7.html#learning-objectives",
    "title": "Task 7: Estimating the reproduction number",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the difference between R0 and Rt\nEstimate reproduction numbers from case data\nUse appropriate methods for different data types\nVisualize and interpret reproduction number estimates"
  },
  {
    "objectID": "task7.html#tutorial",
    "href": "task7.html#tutorial",
    "title": "Task 7: Estimating the reproduction number",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task7.html#downloading-rt-estimates",
    "href": "task7.html#downloading-rt-estimates",
    "title": "Task 7: Estimating the reproduction number",
    "section": "Downloading Rt Estimates",
    "text": "Downloading Rt Estimates\nNote: Running EpiNow2 can be computationally expensive and may take several minutes to complete. If you want to skip this step, you can download the pre-computed estimates file and place it in your outputs/ folder:\nDownload Rt estimates"
  },
  {
    "objectID": "task7.html#example-report",
    "href": "task7.html#example-report",
    "title": "Task 7: Estimating the reproduction number",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\nConverting linelist to incidence\nWe first import linelist data for an Ebola outbreak that started in April 2014, convert it to incidence, and visualise the epidemic curve.\n\n\nCode\n# INSTALL AND LOAD PACKAGES\npacman::p_load(tidyverse, EpiNow2, incidence2, rio, reactable)\n\n# LOAD DATA\n# Import the cleaned linelist data\nlinelist &lt;- readRDS(\"data/linelist.rds\")\n\n# Convert linelist to incidence and format data for EpiNow2\nincidence &lt;- linelist |&gt;\n  incidence2::incidence(\n    date_index = \"date_onset\",\n    count_values_to = \"confirm\",\n    date_names_to = \"date\",\n    complete_dates = TRUE\n  ) |&gt;\n  # Keep the first 90 dates\n  dplyr::slice_head(n = 190)\n\n# Plotting incidence curve\nplot(incidence) +\n  labs(x = \"Date\", y = \"Cases\")\n\n\n\n\n\n\n\n\n\n\n\nEstimating Rt\nWe used {EpiNow2} to estimate the time-varying reproduction number (Rt) for the Ebola outbreak, accounting for reporting delays. We first defined the parameters.\n\n\nCode\n# define parameters\npars &lt;- tibble(\n  par = c(\"Incubation Period\", \"Reporting Delay\", \"Generation Time\"),\n  dist = c(\"Gamma\", \"LogNormal\", \"LogNormal\"),\n  mean = c(4, 2, 3),\n  sd = c(2, 1, 2.5),\n  max = c(20, 10, 15)\n)\n\n# Creating distribution objects for the incubation period, reporting delay, and\n# generation time\nincubation_period_fixed &lt;- EpiNow2::Gamma(\n  mean = pars$mean[1],\n  sd = pars$sd[1],\n  max = pars$max[1]\n)\n\nreporting_delay_fixed &lt;- EpiNow2::LogNormal(\n  mean = pars$mean[2],\n  sd = pars$sd[2],\n  max = pars$max[2]\n)\n\ngeneration_time_fixed &lt;- EpiNow2::LogNormal(\n  mean = pars$mean[3],\n  sd = pars$sd[3],\n  max = pars$max[3]\n)\n\n# define Rt prior distribution\nrt_prior &lt;- EpiNow2::rt_opts(\n  prior = EpiNow2::LogNormal(mean = 1.5, sd = 0.2)\n)\n\n# print table\nreactable(\n  pars,\n  columns = list(\n    par = colDef(name = \"Parameter\"),\n    dist = colDef(name = \"Distribution\"),\n    mean = colDef(name = \"Mean\"),\n    sd = colDef(name = \"Standard Deviation\"),\n    max = colDef(name = \"Maximum\")\n  )\n)\n\n\n\n\n\n\nThe estimated time-varying reproduction number is visualised below.\n\n\nCode\n# check if the analysis has been run before and run EpiNow2 if not\nfile_name &lt;- \"outputs/rt_estimates.rds\"\nif (file.exists(file_name)) {\n  rt_estimates &lt;- import(file_name)\n} else {\n  # define cores\n  withr::local_options(base::list(mc.cores = 4))\n  ## generate estimates\n  rt_estimates &lt;- EpiNow2::epinow(\n    # # Drop column for {EpiNow2} input format\n    data = select(incidence, -count_variable),\n    # delays\n    generation_time = EpiNow2::generation_time_opts(generation_time_fixed),\n    delays = EpiNow2::delay_opts(\n      incubation_period_fixed + reporting_delay_fixed\n    ),\n    # prior\n    rt = rt_prior,\n    stan = EpiNow2::stan_opts(samples = 1000, chains = 3)\n  )\n  export(rt_estimates, file_name)\n}\n\n# plot reproduction number\nrt_estimates$plots$R\n\n\n\n\n\n\n\n\n\nKey summary statistics are provided below:\n\n\nCode\n# generate an interactive table\nreactable(\n  summary(rt_estimates),\n  columns = list(\n    measure = colDef(name = \"Measure\"),\n    estimate = colDef(name = \"Estimate\")\n  )\n)"
  },
  {
    "objectID": "task5.html",
    "href": "task5.html",
    "title": "Task 5: Getting epidemiological parameters",
    "section": "",
    "text": "This task focuses on obtaining epidemiological parameters from your data or the literature. You will learn how to extract, estimate, and use key epidemiological parameters in your analyses."
  },
  {
    "objectID": "task5.html#overview",
    "href": "task5.html#overview",
    "title": "Task 5: Getting epidemiological parameters",
    "section": "",
    "text": "This task focuses on obtaining epidemiological parameters from your data or the literature. You will learn how to extract, estimate, and use key epidemiological parameters in your analyses."
  },
  {
    "objectID": "task5.html#learning-objectives",
    "href": "task5.html#learning-objectives",
    "title": "Task 5: Getting epidemiological parameters",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExtract epidemiological parameters from data\nSearch and retrieve parameters from literature\nEstimate parameters using available data\nIncorporate parameters into analytical models"
  },
  {
    "objectID": "task5.html#tutorial",
    "href": "task5.html#tutorial",
    "title": "Task 5: Getting epidemiological parameters",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task5.html#example-report",
    "href": "task5.html#example-report",
    "title": "Task 5: Getting epidemiological parameters",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\nEbola serial interval\nThe serial interval for Ebola was extracted from the epiparameter package, identifying the following source:\n\nCode\n# INSTALL AND LOAD PACKAGES\n\n# Load required packages\npacman::p_load(epiparameter, tidyverse, EpiNow2, reactable)\n\n# Creating epiparameter objects by accessing the {epiparameter} library\nebola_serial_int &lt;- epiparameter::epiparameter_db(\n  disease = \"ebola\",\n  epi_name = \"serial\",\n  subset = sample_size &gt; 10,\n  author = \"WHO Ebola Response Team\",\n  single_epiparameter = TRUE\n)\n\nebola_serial_int$citation\n\nWHO Ebola Response Team, Agua-Agum J, Ariyarajah A, Aylward B, Blake I, Brennan R, Cori A, Donnelly C, Dorigatti I, Dye C, Eckmanns T, Ferguson N, Formenty P, Fraser C, Garcia E, Garske T, Hinsley W, Holmes D, Hugonnet S, Iyengar S, Jombart T, Krishnan R, Meijers S, Mills H, Mohamed Y, Nedjati-Gilani G, Newton E, Nouvellet P, Pelletier L, Perkins D, Riley S, Sagrado M, Schnitzler J, Schumacher D, Shah A, Van Kerkhove M, Varsaneux O, Kannangarage N (2015). ‚ÄúWest African Ebola Epidemic after One Year ‚Äî Slowing but Not Yet under Control.‚Äù The New England Journal of Medicine. doi:10.1056/NEJMc1414992 https://doi.org/10.1056/NEJMc1414992.\n\n\nCode\n# Extract summary statistics and parameters\npars &lt;- epiparameter::get_parameters(ebola_serial_int) # distribution parameters\nserial_mean &lt;- ebola_serial_int$summary_stats$mean\nserial_sd &lt;- ebola_serial_int$summary_stats$sd\n\n# Calculate 95th percentile of serial interval\nserial_interval_95th &lt;- qgamma(\n  0.95,\n  shape = pars[\"shape\"],\n  scale = pars[\"scale\"]\n)\n\n\nThis estimate has a mean of 14.2 days and standard deviation of 9.6 days, meaning that 95% of cases have a serial interval of less than 33 days. The probability density function of the serial interval is given below:\n\n\nCode\nplot(ebola_serial_int) # as a plot of the PDF"
  },
  {
    "objectID": "task3.html",
    "href": "task3.html",
    "title": "Task 3: Generating interactive maps",
    "section": "",
    "text": "This task focuses on creating interactive maps for visualizing spatial aspects of epidemiological data. You will learn how to work with spatial data, create maps using GIS tools in R, and visualize disease patterns geographically."
  },
  {
    "objectID": "task3.html#overview",
    "href": "task3.html#overview",
    "title": "Task 3: Generating interactive maps",
    "section": "",
    "text": "This task focuses on creating interactive maps for visualizing spatial aspects of epidemiological data. You will learn how to work with spatial data, create maps using GIS tools in R, and visualize disease patterns geographically."
  },
  {
    "objectID": "task3.html#learning-objectives",
    "href": "task3.html#learning-objectives",
    "title": "Task 3: Generating interactive maps",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nWork with spatial data formats (shapefiles, coordinates)\nCreate interactive maps using GIS tools in R\nVisualize disease patterns and hotspots geographically\nPerform basic spatial analysis"
  },
  {
    "objectID": "task3.html#tutorial",
    "href": "task3.html#tutorial",
    "title": "Task 3: Generating interactive maps",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task3.html#download-gis-data",
    "href": "task3.html#download-gis-data",
    "title": "Task 3: Generating interactive maps",
    "section": "Download GIS Data",
    "text": "Download GIS Data\nFor this task, you will need the GIS shapefile data to create the maps. The shapefile contains administrative boundaries for Sierra Leone.\n\nDownload the GIS data zip file using the button below.\nUnzip the file and extract its contents to your data/gis/ folder.\nThe extracted files should include sle_adm3.shp and other related shapefile components in the data/gis/ directory.\n\nDownload GIS data (zip)"
  },
  {
    "objectID": "task3.html#example-report",
    "href": "task3.html#example-report",
    "title": "Task 3: Generating interactive maps",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\nGeographic distribution of cases\n\n\nCode\n# INSTALL AND LOAD PACKAGES\n\n# Load required packages\npacman::p_load(\n  tidyverse, # basic data manipulation\n  sf, # handling shapefiles\n  here, # handing file paths\n  leaflet, # mapping\n  leaflet.extras, # additional leaflet features including heatmaps\n  htmltools, # handlers for html objects\n  janitor # name cleaning\n)\n\n\n# LOAD DATA\n\n# load shapefiles and keep relevant areas\nshp &lt;- sf::read_sf(\"data/gis/sle_adm3.shp\") |&gt;\n  # standardize column names\n  janitor::clean_names()\n\n# import the cleaned linelist data\nlinelist &lt;- rio::import(\"data/linelist.rds\")\n\n# convert to aggregate format\nagg &lt;- linelist |&gt;\n  # count the number of cases per adm3\n  summarise(n = n(), .by = adm3) |&gt;\n  # add the shape files of the adm3 zones\n  inner_join(shp, by = c(adm3 = \"adm3_en\")) |&gt;\n  # convert back to shapefile\n  st_as_sf()\n\n\nTotal incidence to date was mapped by chiefdom.\n\n\nCode\n# define colour palette\npal &lt;- colorNumeric(palette = \"YlOrRd\", domain = agg$n)\n\n# generate choropleth map (polygons only)\nleaflet(agg) |&gt;\n  # use CartoDB for background\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  # add adm3 shaded by number of cases\n  addPolygons(\n    fillColor = ~ pal(n),\n    color = \"white\",\n    weight = 1,\n    fillOpacity = 0.7,\n    # define labels\n    label = ~ map(\n      paste0(\"&lt;b&gt;\", adm3, \"&lt;/b&gt;&lt;br&gt;\", n, \" cases\"),\n      htmltools::HTML\n    ),\n    labelOptions = labelOptions(direction = \"auto\"),\n    highlightOptions = highlightOptions(\n      weight = 3,\n      color = \"black\",\n      bringToFront = FALSE\n    )\n  ) |&gt;\n  # add legend\n  addLegend(\n    pal = pal,\n    values = ~n,\n    title = \"Case count\",\n    opacity = 0.7,\n    position = \"bottomright\"\n  )\n\n\n\n\n\n\nSpatial clustering of cases was then investigated at a higher spatial resolution using a heatmap.\n\n\nCode\n# Prepare linelist data for heatmap\n# Filter cases with valid coordinates\nlinelist_coords &lt;- linelist |&gt;\n  filter(!is.na(lon), !is.na(lat))\n\n# Generate heatmap from individual cases\nleaflet(linelist_coords) |&gt;\n  # use CartoDB for background\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  # add heatmap layer\n  addHeatmap(\n    lng = ~lon,\n    lat = ~lat,\n    intensity = 0.5,\n    blur = 5,\n    max = 0.05,\n    radius = 7,\n    gradient = c(\"blue\", \"cyan\", \"yellow\", \"red\")\n  )"
  },
  {
    "objectID": "task10.html",
    "href": "task10.html",
    "title": "Task 10: Simulating disease transmission",
    "section": "",
    "text": "This task covers simulating disease spread using mathematical models. You will learn how to generate disease trajectories, set up model parameters, and account for uncertainty in model simulations."
  },
  {
    "objectID": "task10.html#overview",
    "href": "task10.html#overview",
    "title": "Task 10: Simulating disease transmission",
    "section": "",
    "text": "This task covers simulating disease spread using mathematical models. You will learn how to generate disease trajectories, set up model parameters, and account for uncertainty in model simulations."
  },
  {
    "objectID": "task10.html#learning-objectives",
    "href": "task10.html#learning-objectives",
    "title": "Task 10: Simulating disease transmission",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nLoad and use model structures from the epidemics package\nLoad social contact matrices with socialmixr\nGenerate disease spread model simulations\nGenerate multiple model simulations and visualize uncertainty"
  },
  {
    "objectID": "task10.html#tutorial",
    "href": "task10.html#tutorial",
    "title": "Task 10: Simulating disease transmission",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task10.html#example-report",
    "href": "task10.html#example-report",
    "title": "Task 10: Simulating disease transmission",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\n\nCode\n# INSTALL AND LOAD PACKAGES\n\n# Install epidemics from GitHub\npacman::p_load_gh(\"epiverse-trace/epidemics\")\n\n# Load required packages\npacman::p_load(tidyverse, epidemics, socialmixr, reactable)\n\n\n\nDefine population demographics and initial population conditions\nWe first extract a social contact matrix from {socialmixr} for the United Kingdom. A single individual from the youngest age category (under 20 years old) was infected and introduced the disease in a population of 1 million, which were initially fully susceptible to the infection.\n\n\nCode\n# Defining social contact matrix\ncontact_data &lt;- socialmixr::contact_matrix(\n  survey = socialmixr::polymod,\n  countries = \"United Kingdom\",\n  age.limits = c(0, 20, 40),\n  symmetric = TRUE\n)\n# prepare contact matrix\ncontact_matrix &lt;- t(contact_data$matrix)\n\n# Define population's initial conditions\ninitial_i &lt;- 1e-6\ninitial_conditions_inf &lt;- c(\n  S = 1 - initial_i, E = 0, I = initial_i, R = 0, V = 0\n)\ninitial_conditions_free &lt;- c(\n  S = 1, E = 0, I = 0, R = 0, V = 0\n)\n\n# combine the initial conditions\ninitial_conditions &lt;- rbind(\n  initial_conditions_inf, # age group 1\n  initial_conditions_free, # age group 2\n  initial_conditions_free # age group 3\n)\n\n# use contact matrix to assign age group names\nrownames(initial_conditions) &lt;- rownames(contact_matrix)\n\n# Create demography vector\ndemography_vector &lt;- contact_data$demography$population\nnames(demography_vector) &lt;- rownames(contact_matrix)\n\n# Create population object for {epidemics}\nuk_population &lt;- population(\n  name = \"UK\",\n  contact_matrix = contact_matrix,\n  demography_vector = demography_vector,\n  initial_conditions = initial_conditions\n)\n\n\nHere we see the demography:\n\n\nCode\nenframe(uk_population$demography_vector, \"Age group\", \"Population\") |&gt;\n  reactable(fullWidth = FALSE)\n\n\n\n\n\n\nHere we see the contact matrix:\n\n\nCode\nround(uk_population$contact_matrix, 1) |&gt;\n  reactable(fullWidth = FALSE)\n\n\n\n\n\n\nAnd here the initial conditions:\n\n\nCode\nuk_population$initial_conditions |&gt;\n  reactable(fullWidth = FALSE)\n\n\n\n\n\n\n\n\nSimulating transmission\nWe fitted an SEIR to model the transmission of an infectious disease with a basic reproduction number of 1.5, an infectious period of 7 days, and a pre-infectious period of 3 days.\n\n\nCode\n# Defining model parameters\n# time periods\npreinfectious_period &lt;- 3.0\ninfectious_period &lt;- 7.0\n\n# specify the mean and standard deviation of R0\nr_estimate_mean &lt;- 1.5\nr_estimate_sd &lt;- 0.05\n\n# Generate 100 R samples\nr_samples &lt;- withr::with_seed(\n  seed = 1,\n  rnorm(\n    n = 100, mean = r_estimate_mean, sd = r_estimate_sd\n  )\n)\n\n# rates\ninfectiousness_rate &lt;- 1.0 / preinfectious_period\nrecovery_rate &lt;- 1.0 / infectious_period\nbeta &lt;- r_samples / infectious_period\n\n# running {epidemic} default model\noutput &lt;- model_default(\n  population = uk_population,\n  transmission_rate = beta,\n  infectiousness_rate = infectiousness_rate,\n  recovery_rate = recovery_rate,\n  time_end = 600, increment = 1\n)\n\n# Visualising output\noutput %&gt;%\n  mutate(r_value = r_samples) %&gt;%\n  unnest(data) %&gt;%\n  filter(compartment == \"infectious\") %&gt;%\n  ggplot() +\n  geom_line(\n    aes(time, value, color = r_value, group = param_set),\n    alpha = 3\n  ) +\n  scale_color_fermenter(\n    palette = \"RdBu\",\n    name = \"R\"\n  ) +\n  scale_y_continuous(\n    labels = scales::comma\n  ) +\n  facet_grid(\n    cols = vars(demography_group)\n  ) +\n  theme_bw() +\n  labs(\n    x = \"Simulation time (days)\",\n    y = \"Individuals\"\n  )\n\n\n\n\n\n\n\n\n\nThe figure above shows the total number or cumulative amount of individuals in the infectious compartment at each time, across the 100 simulations run for different basic reproduction number values."
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "To get started, you‚Äôll need to install R and RStudio on your computer.\nFor installation instructions and downloads, please visit: Epiverse-TRACE Software Setup. This guide will assist you with installing R and RStudio, including checking your R version and updating if needed.\n\n\nIf you‚Äôre unable to install R and RStudio on your laptop, you can use Posit Cloud instead: this provide a free cloud-based RStudio environment that you can access from any web browser."
  },
  {
    "objectID": "setup.html#installing-r-and-rstudio",
    "href": "setup.html#installing-r-and-rstudio",
    "title": "Setup",
    "section": "",
    "text": "To get started, you‚Äôll need to install R and RStudio on your computer.\nFor installation instructions and downloads, please visit: Epiverse-TRACE Software Setup. This guide will assist you with installing R and RStudio, including checking your R version and updating if needed.\n\n\nIf you‚Äôre unable to install R and RStudio on your laptop, you can use Posit Cloud instead: this provide a free cloud-based RStudio environment that you can access from any web browser."
  },
  {
    "objectID": "setup.html#installing-r-packages",
    "href": "setup.html#installing-r-packages",
    "title": "Setup",
    "section": "Installing R Packages",
    "text": "Installing R Packages\nBefore setting up your project, you‚Äôll need to install some essential R packages. We‚Äôll use pacman, a package management tool for R that simplifies installing and loading packages. Pacman automatically installs packages if they‚Äôre not already installed, then loads them - making it much easier to manage dependencies.\nRun the following code in your R console to install pacman (if needed) and then install the essential packages:\n# Install pacman if needed\nif (!requireNamespace(\"pacman\", quietly = TRUE)) {\n  install.packages(\"pacman\")\n}\n\n# Install essential packages using pacman\npacman::p_load(\n  tidyverse,  # For data manipulation and visualization\n  rmarkdown   # For creating reports (required for Quarto)\n)\nNote: Additional packages will be installed as you work through specific tasks. For now, these two packages are sufficient to get started."
  },
  {
    "objectID": "setup.html#setting-up-your-project",
    "href": "setup.html#setting-up-your-project",
    "title": "Setup",
    "section": "Setting Up Your Project",
    "text": "Setting Up Your Project\nBefore you begin working on the tasks, let‚Äôs set up your RStudio project and folder structure.\n\nStep 1: Create an RStudio R Project\nAn R Project is a way to organize your work in RStudio. It helps keep all your files, data, and outputs together in one place, and automatically sets your working directory so file paths work correctly.\n\nOpen RStudio.\nGo to File ‚Üí New Project.\nSelect New Directory.\nSelect New Project.\nIn the ‚ÄúDirectory name‚Äù field, enter sitrep.\nChoose a location on your computer where you want to save the project.\nClick Create Project.\n\nRStudio will now open your new project. You‚Äôll see the project name (sitrep) in the top-right corner of RStudio.\n\n\nStep 2: Set Up Your Folder Structure\nWithin your project, create the following subfolders to organize your files:\n\nIn RStudio, click the Files tab in the bottom-right pane.\nClick New Folder.\nCreate a folder called data/ - for storing your datasets.\nCreate a folder called outputs/ - for storing generated reports and figures.\nCreate a folder called scripts/ - for storing your R scripts."
  },
  {
    "objectID": "setup.html#download-cleaned-dataset",
    "href": "setup.html#download-cleaned-dataset",
    "title": "Setup",
    "section": "Download Cleaned Dataset",
    "text": "Download Cleaned Dataset\nThis is an example dataset resembling a fictional Ebola outbreak that will be used in the various examples throughout the workshop tasks. The dataset is from the Applied Epi R Handbook and contains a cleaned case linelist with epidemiological data including case demographics, dates, locations, and outcomes.\nDownload clean linelist\nAfter downloading, place the file in your data/ folder. The example code in each analysis task is already set up to work with this dataset structure."
  },
  {
    "objectID": "setup.html#next-steps",
    "href": "setup.html#next-steps",
    "title": "Setup",
    "section": "Next Steps",
    "text": "Next Steps\nOnce you have the basics set up:\n\nIf you want a refresher on the basics of R, visit the Intro to R section.\nIf you are interested in the basics of data wrangling, visit the data importing or cleaning pages.\nIf you are interested in analytics, explore the analysis tab to find the tasks you‚Äôre interested in."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Collaborative Analytics Workshop",
    "section": "",
    "text": "Welcome to the Collaborative Analytics Workshop! This workshop is designed to help you explore different tools and resources for conducting a range of common epidemiological analytical tasks. Our primary goal is for you to take home a functional script that generates an interactive epidemiological situation report that you can build on and adapt for your own work moving forward.\n\nWorkshop Agenda\nThis is a single-day workshop running from 9:00 AM to 5:00 PM. You will be grouped by the datasets you are working on to facilitate collaboration and peer support. Throughout the day, facilitators will be available to provide guidance and answer questions.\nIn the first half of the day, you will work on rendering your first automated situation report. In the second half of the day, you will work through one or two more advanced analytical tasks based on your interests and needs. The day will be structured as follows:\n\n\n\nTime\nDuration\nActivity\n\n\n\n\n9:00 - 9:30\n30 min\nWelcome, introduction, divide into groups\n\n\n9:30 - 10:30\n60 min\nComplete Setup\n\n\n10:30 - 11:00\n30 min\nMorning tea\n\n\n11:00 - 12:00\n60 min\nComplete first task\n\n\n12:00 - 12:30\n30 min\nRegroup and discuss progress\n\n\n12:30 - 13:30\n60 min\nLunch break\n\n\n13:30 - 15:00\n90 min\nComplete second task\n\n\n15:00 - 15:30\n30 min\nAfternoon break\n\n\n15:30 - 17:00\n90 min\nComplete third task\n\n\n\n\n\nWorkflow\nEveryone should start by working through the Setup page to get the correct folder structure set up. Then you can pick one or more of the following options:\n\nOption A: Intro to R\nIf you are a beginner to R, you can work through the Intro to R tutorial to learn the basics.\n\n\nOption B: Data Import & Cleaning\n\nIf you are interested in downloading data from sources such as DHIS2 or SORMAS, work through the Data Import tutorial.\nIf you are interested in cleaning data, work through the Data Cleaning tutorial.\n\n\n\nOption C: Report Generation & Analytics\nIf you are automated in automated report generation and analytics, there are 10 tutorials that are available to you. Start with the first and then work through others that interest you:\n\nSetting up an automated report\nBasic descriptive analyses\nGenerating interactive maps\nVisualising transmission chains\nGetting epidemiological parameters\nEstimating disease severity\nEstimating the reproduction number\nNowcasting epidemiological data\nForecasting cases and deaths\nSimulating disease transmission\n\nEach task page includes:\n\nLinks to external tutorials that provide comprehensive learning materials and detailed explanations of the analytical concepts and methods.\nComplete example code that generates all the outputs needed for an example report. The example code works with the provided example datasets\n\nYou can work with your own data throughout the workshop or you can use the example datasets provided. If you don‚Äôt have your own dataset or don‚Äôt feel comfortable adapting code to your data, you can use the example datasets and example code. This will still allow you to learn the analytical techniques and generate a functional report you can reference later.\n\n\n\nAdditional Resources\n\nEpidemiologist R Handbook: A comprehensive guide to R fundamentals for epidemiologists\nR for Data Science: A general introduction to R and coding"
  },
  {
    "objectID": "data_clean.html",
    "href": "data_clean.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Data cleaning is a crucial step in any epidemiological analysis. Before you can analyze your data, you need to ensure it is properly formatted, validated, and ready for analysis. This involves handling missing values, standardizing formats, validating data quality, and preparing data for epidemiological analysis."
  },
  {
    "objectID": "data_clean.html#overview",
    "href": "data_clean.html#overview",
    "title": "Data Cleaning",
    "section": "",
    "text": "Data cleaning is a crucial step in any epidemiological analysis. Before you can analyze your data, you need to ensure it is properly formatted, validated, and ready for analysis. This involves handling missing values, standardizing formats, validating data quality, and preparing data for epidemiological analysis."
  },
  {
    "objectID": "data_clean.html#learning-objectives",
    "href": "data_clean.html#learning-objectives",
    "title": "Data Cleaning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nClean messy datasets\nValidate data quality\nHandle missing values\nStandardize data formats\nPrepare data for epidemiological analysis"
  },
  {
    "objectID": "data_clean.html#example-dataset",
    "href": "data_clean.html#example-dataset",
    "title": "Data Cleaning",
    "section": "Example Dataset",
    "text": "Example Dataset\nFirst download the messy linelist to practice data cleaning and place it in the data/ folder.\nDownload raw linelist"
  },
  {
    "objectID": "data_clean.html#tutorial",
    "href": "data_clean.html#tutorial",
    "title": "Data Cleaning",
    "section": "Tutorial",
    "text": "Tutorial\nThen move on to the tutorial: access here"
  },
  {
    "objectID": "data_import.html",
    "href": "data_import.html",
    "title": "Importing data from HIS",
    "section": "",
    "text": "Many epidemiological datasets are stored in health information systems (HIS) such as DHIS2 or SORMAS. These systems provide application program interfaces (APIs) that allow verified users to import data directly into R for analysis, which is particularly well-suited for collecting and storing large-scale institutional health data."
  },
  {
    "objectID": "data_import.html#overview",
    "href": "data_import.html#overview",
    "title": "Importing data from HIS",
    "section": "",
    "text": "Many epidemiological datasets are stored in health information systems (HIS) such as DHIS2 or SORMAS. These systems provide application program interfaces (APIs) that allow verified users to import data directly into R for analysis, which is particularly well-suited for collecting and storing large-scale institutional health data."
  },
  {
    "objectID": "data_import.html#learning-objectives",
    "href": "data_import.html#learning-objectives",
    "title": "Importing data from HIS",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nRead data from databases and other sources\nImport data from DHIS2 and SORMAS via their API using the readepi package"
  },
  {
    "objectID": "data_import.html#tutorial",
    "href": "data_import.html#tutorial",
    "title": "Importing data from HIS",
    "section": "Tutorial",
    "text": "Tutorial\nStart by installing the readepi package:\n\ninstall.packages(\"readepi\")\n\nThen move on to the tutorial: access here"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction to R",
    "section": "",
    "text": "One of the most important uses of any statistical software, including R, is to analyse data that you may have collected yourself or that have been given to you. In this section, We will introduce how to use R to access data that you already have on your computer, and how to store the results of your analysis or save an updated version of the data, on your computer.\n\n\nYour R studio session will have four main panels:\n\nScript (top-left) - this is where you can write, save and run longer bits of code.\nEnvironment (top-right) - this is where you can see objects that you have created in your current R session.\nConsole (bottom-left) - this is where you can write and run very short bits of code.\nFiles, plots, etc (bottom-right) - this is where you can see your files, or where plots will appear.\n\n\n\n\nThis section introduces the commands to do simple operations in R, such as arithmetic, or how to make objects.\n\n\nThese operators are used to carry out mathematical operations, like addition or multiplication:\n\n+: addition\n-: subtraction\n*: multiplication\n/: division\n^: exponent\n\nExamples:\n\n46 + 3\n13 / 8\n2^5\n\nüíª Try using some of these operators in your R Studio console (the bottom-left panel).\n\n\n\n‚≠ê The assignment operator in R is &lt;- and is used to assign values to named objects.\n‚≠ê If you run every line in the console (bottom left panel), you will not easily see the previous lines of code, that‚Äôs why we use the script (top left panel).\n\nTo execute a line of code from your script: place your cursor on the line you want to run and click on run (top right of the script panel) OR place your cursor and use the shortcut CTRL+ENTER (CMD+ENTER on Mac).\nTo run multiple lines of code, select them with your mouse, and use CTRL+ENTER (or click on run).\nTo run the whole script, use source (top right of the script panel), or use the shortcut CTRL+SHIFT+ENTER (CMD+SHIFT+ENTER on Mac)\n\n\nx &lt;- 10 # The object called x is assigned the value 10\nx # Print the object x\n\ny &lt;- 10 + 20 # The object called y is assigned the value 10 + 20\ny # Print the object y\n\nz &lt;- \"hello\" # The object called z is assigned the text \"hello\"\nz # Print the object z\n\nüíª Look at your Environment panel (top-right) of your R Studio session, then run the above code in your console. Look in the environment panel again: what has changed?\nNote that the names of objects are case sensitive (i.e.¬†Y and y are distinct names) and must not start with numbers or contain spaces. The best approach is to use meaningful object names and stick to using all lower case; if you need to use spaces, then you can use an underscore (_).\n\nExamples of good object names: raw_data, clean_data, country_names.\nExamples of bad object names: raw data, CLEAN_data, dasyg, 1x.\n\n‚ùì Discuss why each of the examples of bad object names are bad.\nüíª Try making some of your own objects, e.g.¬†assign the value \"2025\" to the object year.\n\n\n\nRelational operators are used to compare different values:\n\n&lt; less than\n&gt; greater than\n&lt;= less than or equal to\n&gt;= greater than or equal to\n== equal to\n!= not equal to\n\nExpressions using relational operators will return TRUE or FALSE.\nüíª Copy the below code into the console of your R Studio terminal.\n\nx &lt;- 3 # Assign the value 3 to the object called x\ny &lt;- 11 # Assign the value 11 to the object called y\n\nExamples of using relational operators:\n\n# Test: is x less than 4?\nx &lt; 4\n\n# Test: is y greater than or equal to x\ny &gt;= x\n\n# Test: is x equal to 5?\nx == 5\n\n# Test: is y not equal to 22\ny != 22\n\nüíª Try using some of these operators in your R Studio console, e.g.¬†to test if 2^11 is bigger than 3*729.\n\n\n\nThe c() function is used to combine multiple values into a vector or a list. For example, multiple numeric values can be combined into a vector:\n\nc(3, 1, 10.5)\n\nMultiple text strings can also be combined:\n\nc(\"Welcome\", \"to\", \"R\", \"!\")\n\nA vector can be assigned to an object, elements of the vector are accessed with brackets []:\n\na &lt;- c(5, 4, 10)\na[1]\na[2] + 3\n\n‚ùì What is the value of the third element of a?\nüíª Try running a + 3, what results do you get?\nIf both numbers and text are combined with the c() function, then all the numeric values are transformed into text:\n\nb &lt;- c(\"AFRO\", 4)\nb\n\n‚ùì When running b, how do you see that the second element was transformed into text?\n‚ùì What happens if you try adding 2 to the second element of b? Why?\n\n\n\n\nDatasets are usually stored as data frames, which are objects that can contain several columns (i.e.¬†features) of different types. In this section, we will import a dataframe, and introduce basic functions to inspect the data contained in the dataset.\nThere are several ways to import data into R, in this session we will import a dataset from a local file. In future sessions, we will explore how to import datasets from online sources or packages.\nFor this example, we will use a cleaned case linelist dataset that contains epidemiological data from an outbreak. First, we need to load the data using the readRDS() function, which reads R data files.\n\n# Load the linelist data\nlinelist &lt;- readRDS(\"data/linelist.rds\")\n\nThe linelist contains case data with multiple variables. We want to only focus on a few columns for this exercise, so we‚Äôre going to select these columns. You can check the column names of a dataframe by using the function colnames():\n\ncolnames(linelist)\n\nWe only want to select the case ID, administrative region, age, weight, and gender. Therefore, we create a new object, data_cases, which contains the columns of interest. We use the brackets to indicate the columns we are interested in.\n\ndata_cases &lt;- linelist[, c(\"case_id\", \"adm1\", \"age_years\", \"wt_kg\", \"gender\")]\n\ndata_cases contains all the rows included in linelist, but only the columns case_id, adm1, age_years, wt_kg, and gender. As previously discussed, we should avoid using upper case characters, spaces, brackets, and parentheses when naming objects, since that leads to errors when we try to access these objects. The column names in our dataset already follow good naming conventions, so we don‚Äôt need to rename them.\nNow we have imported our data, we can look at it in one of two ways:\n\nüíª Click on the data_cases object in the ‚ÄòEnvironment‚Äô panel (top-right). A new window will open in front of your script pane showing the data. Have a look!\nüíª Run the command data_cases in your Rstudio console. The data will print in the console. Alternatively, the command head(data_cases) will print the top 6 lines only:\n\n\nhead(data_cases)\n\nNotice that there are NA values in some columns. These indicate missing values, where no data is available.\nYou can also get the number of columns and number of rows in the data set with ncol() and nrow(), respectively:\n\nncol(data_cases)\n\nüíª Use nrow() to find the number of the rows in the data data_cases.\nSometimes we might just be interested in the values of a single column. To extract the values in a single column, we use the $ operator, e.g.¬†data_cases$case_id will return all the values in the column called case_id.\nüíª Run the commands data_cases$case_id and data_cases$wt_kg in your R console to see what outputs you get (hint: you can use head(data_cases$case_id) to only see the first few values).\n\n\nObjects in R are assigned a data type, which tells R how to handle the object.\nThe simplest data types that you will commonly come across are:\n\ncharacter i.e.¬†text, e.g.¬†\"f\" or \"London\"\nnumeric and integer, e.g.¬†2L, 1:10, 2.1, pi\ndate e.g.¬†Sys.Date()\nlogical i.e.¬†TRUE or FALSE\n\nTo check what data type an object is, use the function class().\n\nclass(data_cases$case_id)\n\nclass(data_cases$wt_kg)\n\n‚ùì What data type is the column ‚Äúage_years‚Äù in the data_cases data? ‚ùì What data type is the column ‚Äúgender‚Äù in the data_cases data?\nüíª Use the function table to compute the number of cases classified as ‚Äúm‚Äù and ‚Äúf‚Äù:\n\ntable(data_cases$gender)\n\nüíª Combine the functions prop.table and table to compute the proportion of cases classified as ‚Äúm‚Äù and ‚Äúf‚Äù:\n\nprop.table(table(data_cases$gender))\n\nMore complex data types can be used to combine multiple bits of data. For instance, objects that contain several elements are called data structures. There are three main types of data structure: - vectors: containing one variable per element (created by the function c(), like when we created a and b in the previous section). - matrices: containing several variables per element (all variables have the same type). - data frames: containing several variables per element (variables can have different types).\ndata_cases contains several variables, of different types (some are characters, others are numeric), it is therefore a data frame. Columns of data frames are vectors:\n‚ùì What would happen if data_cases was a matrix? (hint: try running head(as.matrix(data_cases))).\nOther data types, such as factor and list, can be used and are not covered in this practical.\n\n\n\n\nWith numeric data, we can calculate different summary statistics, such as the maximum and minimum values, the mean value,and the median value.\n\n\nWe can calculate the mean value with the function mean().\nüíª Try running the below command to calculate the mean weight:\n\n# Calculate the mean weight\nmean(data_cases$wt_kg)\n\nThis will return NA - not very helpful! This happens because there are missing values (NA values) in wt_kg - you can see these by inspecting your data again. If there are any missing values in your data, mean() (and many other functions) will simply return NA.\nTo remove these missing (NA) values before calculating the mean, we include the argument na.rm = TRUE:\n\n# Calculate the mean weight\nmean(data_cases$wt_kg, na.rm = TRUE)\n\n‚ùì What happens if you change this so that na.rm = FALSE?\nBy default, the value of the argument na.rm (standing for NA remove) in mean() is set to FALSE, so running mean(data_cases$wt_kg, na.rm = FALSE) is equivalent to mean(data_cases$wt_kg).\nFunctions can have many arguments to tackle specific situations (e.g.¬†how to deal with unreported entries). In order to read the description of the expected arguments and outputs of a function, you can use the operator ?: e.g.¬†?mean. It will open a helpfile, which will contain the list of all compatible arguments, and their default value (if any).\n‚ùì What arguments are compatible with the function mean ?\nWe can calculate other statistics, too. We can calculate the median value with the function median():\n\n# Calculate the median weight\nmedian(data_cases$wt_kg, na.rm = TRUE)\n\nNote that we also have to include the na.rm = TRUE argument so that missing (NA) values are removed before the median is calculated.\nüíª Calculate the mean and median age of the cases in data_cases. You can remind yourself of the other column names by looking at the data, or checking with the function we introduced earlier.\n\n\n\nWe can calculate the minimum and maximum values with the functions min() and max(), respectively:\n\n# Calculate the minimum weight\nmin(data_cases$wt_kg, na.rm = TRUE)\n\n# Calculate the maximum weight\nmax(data_cases$wt_kg, na.rm = TRUE)\n\nüíª Calculate the minimum and maximum age for the cases in data_cases.\n\n\n\nWe can calculate the standard deviation with sd() and the inter-quartile range (IQR) with IQR():\n\n# Calculate the standard deviation of weight\nsd(data_cases$wt_kg, na.rm = TRUE)\n\n# Calculate the IQR of weight\nIQR(data_cases$wt_kg, na.rm = TRUE)\n\nüíª Calculate the standard deviation and inter-quartile range for one of the other numeric columns in the data_cases data.\nA quick way to generate summary statistics for all columns in a data frame is to use the function summary:\n\n# Show the summary of each column in data_cases\nsummary(data_cases)"
  },
  {
    "objectID": "intro.html#r-studio",
    "href": "intro.html#r-studio",
    "title": "Introduction to R",
    "section": "",
    "text": "Your R studio session will have four main panels:\n\nScript (top-left) - this is where you can write, save and run longer bits of code.\nEnvironment (top-right) - this is where you can see objects that you have created in your current R session.\nConsole (bottom-left) - this is where you can write and run very short bits of code.\nFiles, plots, etc (bottom-right) - this is where you can see your files, or where plots will appear."
  },
  {
    "objectID": "intro.html#basic-r-expressions",
    "href": "intro.html#basic-r-expressions",
    "title": "Introduction to R",
    "section": "",
    "text": "This section introduces the commands to do simple operations in R, such as arithmetic, or how to make objects.\n\n\nThese operators are used to carry out mathematical operations, like addition or multiplication:\n\n+: addition\n-: subtraction\n*: multiplication\n/: division\n^: exponent\n\nExamples:\n\n46 + 3\n13 / 8\n2^5\n\nüíª Try using some of these operators in your R Studio console (the bottom-left panel).\n\n\n\n‚≠ê The assignment operator in R is &lt;- and is used to assign values to named objects.\n‚≠ê If you run every line in the console (bottom left panel), you will not easily see the previous lines of code, that‚Äôs why we use the script (top left panel).\n\nTo execute a line of code from your script: place your cursor on the line you want to run and click on run (top right of the script panel) OR place your cursor and use the shortcut CTRL+ENTER (CMD+ENTER on Mac).\nTo run multiple lines of code, select them with your mouse, and use CTRL+ENTER (or click on run).\nTo run the whole script, use source (top right of the script panel), or use the shortcut CTRL+SHIFT+ENTER (CMD+SHIFT+ENTER on Mac)\n\n\nx &lt;- 10 # The object called x is assigned the value 10\nx # Print the object x\n\ny &lt;- 10 + 20 # The object called y is assigned the value 10 + 20\ny # Print the object y\n\nz &lt;- \"hello\" # The object called z is assigned the text \"hello\"\nz # Print the object z\n\nüíª Look at your Environment panel (top-right) of your R Studio session, then run the above code in your console. Look in the environment panel again: what has changed?\nNote that the names of objects are case sensitive (i.e.¬†Y and y are distinct names) and must not start with numbers or contain spaces. The best approach is to use meaningful object names and stick to using all lower case; if you need to use spaces, then you can use an underscore (_).\n\nExamples of good object names: raw_data, clean_data, country_names.\nExamples of bad object names: raw data, CLEAN_data, dasyg, 1x.\n\n‚ùì Discuss why each of the examples of bad object names are bad.\nüíª Try making some of your own objects, e.g.¬†assign the value \"2025\" to the object year.\n\n\n\nRelational operators are used to compare different values:\n\n&lt; less than\n&gt; greater than\n&lt;= less than or equal to\n&gt;= greater than or equal to\n== equal to\n!= not equal to\n\nExpressions using relational operators will return TRUE or FALSE.\nüíª Copy the below code into the console of your R Studio terminal.\n\nx &lt;- 3 # Assign the value 3 to the object called x\ny &lt;- 11 # Assign the value 11 to the object called y\n\nExamples of using relational operators:\n\n# Test: is x less than 4?\nx &lt; 4\n\n# Test: is y greater than or equal to x\ny &gt;= x\n\n# Test: is x equal to 5?\nx == 5\n\n# Test: is y not equal to 22\ny != 22\n\nüíª Try using some of these operators in your R Studio console, e.g.¬†to test if 2^11 is bigger than 3*729.\n\n\n\nThe c() function is used to combine multiple values into a vector or a list. For example, multiple numeric values can be combined into a vector:\n\nc(3, 1, 10.5)\n\nMultiple text strings can also be combined:\n\nc(\"Welcome\", \"to\", \"R\", \"!\")\n\nA vector can be assigned to an object, elements of the vector are accessed with brackets []:\n\na &lt;- c(5, 4, 10)\na[1]\na[2] + 3\n\n‚ùì What is the value of the third element of a?\nüíª Try running a + 3, what results do you get?\nIf both numbers and text are combined with the c() function, then all the numeric values are transformed into text:\n\nb &lt;- c(\"AFRO\", 4)\nb\n\n‚ùì When running b, how do you see that the second element was transformed into text?\n‚ùì What happens if you try adding 2 to the second element of b? Why?"
  },
  {
    "objectID": "intro.html#inspecting-data-frames",
    "href": "intro.html#inspecting-data-frames",
    "title": "Introduction to R",
    "section": "",
    "text": "Datasets are usually stored as data frames, which are objects that can contain several columns (i.e.¬†features) of different types. In this section, we will import a dataframe, and introduce basic functions to inspect the data contained in the dataset.\nThere are several ways to import data into R, in this session we will import a dataset from a local file. In future sessions, we will explore how to import datasets from online sources or packages.\nFor this example, we will use a cleaned case linelist dataset that contains epidemiological data from an outbreak. First, we need to load the data using the readRDS() function, which reads R data files.\n\n# Load the linelist data\nlinelist &lt;- readRDS(\"data/linelist.rds\")\n\nThe linelist contains case data with multiple variables. We want to only focus on a few columns for this exercise, so we‚Äôre going to select these columns. You can check the column names of a dataframe by using the function colnames():\n\ncolnames(linelist)\n\nWe only want to select the case ID, administrative region, age, weight, and gender. Therefore, we create a new object, data_cases, which contains the columns of interest. We use the brackets to indicate the columns we are interested in.\n\ndata_cases &lt;- linelist[, c(\"case_id\", \"adm1\", \"age_years\", \"wt_kg\", \"gender\")]\n\ndata_cases contains all the rows included in linelist, but only the columns case_id, adm1, age_years, wt_kg, and gender. As previously discussed, we should avoid using upper case characters, spaces, brackets, and parentheses when naming objects, since that leads to errors when we try to access these objects. The column names in our dataset already follow good naming conventions, so we don‚Äôt need to rename them.\nNow we have imported our data, we can look at it in one of two ways:\n\nüíª Click on the data_cases object in the ‚ÄòEnvironment‚Äô panel (top-right). A new window will open in front of your script pane showing the data. Have a look!\nüíª Run the command data_cases in your Rstudio console. The data will print in the console. Alternatively, the command head(data_cases) will print the top 6 lines only:\n\n\nhead(data_cases)\n\nNotice that there are NA values in some columns. These indicate missing values, where no data is available.\nYou can also get the number of columns and number of rows in the data set with ncol() and nrow(), respectively:\n\nncol(data_cases)\n\nüíª Use nrow() to find the number of the rows in the data data_cases.\nSometimes we might just be interested in the values of a single column. To extract the values in a single column, we use the $ operator, e.g.¬†data_cases$case_id will return all the values in the column called case_id.\nüíª Run the commands data_cases$case_id and data_cases$wt_kg in your R console to see what outputs you get (hint: you can use head(data_cases$case_id) to only see the first few values).\n\n\nObjects in R are assigned a data type, which tells R how to handle the object.\nThe simplest data types that you will commonly come across are:\n\ncharacter i.e.¬†text, e.g.¬†\"f\" or \"London\"\nnumeric and integer, e.g.¬†2L, 1:10, 2.1, pi\ndate e.g.¬†Sys.Date()\nlogical i.e.¬†TRUE or FALSE\n\nTo check what data type an object is, use the function class().\n\nclass(data_cases$case_id)\n\nclass(data_cases$wt_kg)\n\n‚ùì What data type is the column ‚Äúage_years‚Äù in the data_cases data? ‚ùì What data type is the column ‚Äúgender‚Äù in the data_cases data?\nüíª Use the function table to compute the number of cases classified as ‚Äúm‚Äù and ‚Äúf‚Äù:\n\ntable(data_cases$gender)\n\nüíª Combine the functions prop.table and table to compute the proportion of cases classified as ‚Äúm‚Äù and ‚Äúf‚Äù:\n\nprop.table(table(data_cases$gender))\n\nMore complex data types can be used to combine multiple bits of data. For instance, objects that contain several elements are called data structures. There are three main types of data structure: - vectors: containing one variable per element (created by the function c(), like when we created a and b in the previous section). - matrices: containing several variables per element (all variables have the same type). - data frames: containing several variables per element (variables can have different types).\ndata_cases contains several variables, of different types (some are characters, others are numeric), it is therefore a data frame. Columns of data frames are vectors:\n‚ùì What would happen if data_cases was a matrix? (hint: try running head(as.matrix(data_cases))).\nOther data types, such as factor and list, can be used and are not covered in this practical."
  },
  {
    "objectID": "intro.html#basic-operations-with-numeric-data",
    "href": "intro.html#basic-operations-with-numeric-data",
    "title": "Introduction to R",
    "section": "",
    "text": "With numeric data, we can calculate different summary statistics, such as the maximum and minimum values, the mean value,and the median value.\n\n\nWe can calculate the mean value with the function mean().\nüíª Try running the below command to calculate the mean weight:\n\n# Calculate the mean weight\nmean(data_cases$wt_kg)\n\nThis will return NA - not very helpful! This happens because there are missing values (NA values) in wt_kg - you can see these by inspecting your data again. If there are any missing values in your data, mean() (and many other functions) will simply return NA.\nTo remove these missing (NA) values before calculating the mean, we include the argument na.rm = TRUE:\n\n# Calculate the mean weight\nmean(data_cases$wt_kg, na.rm = TRUE)\n\n‚ùì What happens if you change this so that na.rm = FALSE?\nBy default, the value of the argument na.rm (standing for NA remove) in mean() is set to FALSE, so running mean(data_cases$wt_kg, na.rm = FALSE) is equivalent to mean(data_cases$wt_kg).\nFunctions can have many arguments to tackle specific situations (e.g.¬†how to deal with unreported entries). In order to read the description of the expected arguments and outputs of a function, you can use the operator ?: e.g.¬†?mean. It will open a helpfile, which will contain the list of all compatible arguments, and their default value (if any).\n‚ùì What arguments are compatible with the function mean ?\nWe can calculate other statistics, too. We can calculate the median value with the function median():\n\n# Calculate the median weight\nmedian(data_cases$wt_kg, na.rm = TRUE)\n\nNote that we also have to include the na.rm = TRUE argument so that missing (NA) values are removed before the median is calculated.\nüíª Calculate the mean and median age of the cases in data_cases. You can remind yourself of the other column names by looking at the data, or checking with the function we introduced earlier.\n\n\n\nWe can calculate the minimum and maximum values with the functions min() and max(), respectively:\n\n# Calculate the minimum weight\nmin(data_cases$wt_kg, na.rm = TRUE)\n\n# Calculate the maximum weight\nmax(data_cases$wt_kg, na.rm = TRUE)\n\nüíª Calculate the minimum and maximum age for the cases in data_cases.\n\n\n\nWe can calculate the standard deviation with sd() and the inter-quartile range (IQR) with IQR():\n\n# Calculate the standard deviation of weight\nsd(data_cases$wt_kg, na.rm = TRUE)\n\n# Calculate the IQR of weight\nIQR(data_cases$wt_kg, na.rm = TRUE)\n\nüíª Calculate the standard deviation and inter-quartile range for one of the other numeric columns in the data_cases data.\nA quick way to generate summary statistics for all columns in a data frame is to use the function summary:\n\n# Show the summary of each column in data_cases\nsummary(data_cases)"
  },
  {
    "objectID": "intro.html#importing-data-with-rio",
    "href": "intro.html#importing-data-with-rio",
    "title": "Introduction to R",
    "section": "5.1 Importing data with rio",
    "text": "5.1 Importing data with rio\nWe can import (i.e.¬†‚Äòread in‚Äô) and export (i.e.¬†save) data in common formats (e.g.¬†.csv, .xlsx, .txt) with the rio package. In this section, we are going to import some data on life expectancy at birth and health expenditure per capita in USD for countries in 2015. This data is from Our World in Data and we will be downloaded directly from the website using the URL provided by their data API:\n‚≠ê We import a data file (e.g.¬†.csv) using the import() function from the rio library.\nüíª Copy and paste the code below. This code imports the data life_expectancy.csv from the website and assigns it to an object called life_expectancy:\n\nlife_expectancy &lt;- rio::import(\n  file = \"https://ourworldindata.org/grapher/life-expectancy-vs-health-expenditure.csv?v=1&csvType=full&useColumnShortNames=true\"\n)\n\nInspect the data using the head() function:\n\n\n\n\n\n\nLet‚Äôs look more closely at how import() works.\n\n5.1.1 The import() function\nThe import() function has one main argument: file. This argument is where we tell R where to find the file we want to import.\nIf you use R a lot, you might see people using other functions or libraries, such as the function read.csv() for .csv files only, or the library readxl for .xls or .xlsx files only. But one of the great things about import() is that you can use it for all common data formats e.g.¬†.csv, .txt, .xlsx, so you only have to remember that!"
  },
  {
    "objectID": "intro.html#exporting-data",
    "href": "intro.html#exporting-data",
    "title": "Introduction to R",
    "section": "5.2 Exporting data",
    "text": "5.2 Exporting data\n‚≠ê We export data using the export() function from the rio library.\nThe argument x specified the name of the data (e.g.¬†the data frame) that we want to export. The argument file tells R where to save the data and what to call it.\nThe code below exports the data frame life_expectancy and saves it as a .csv file called ‚Äútest_data_export.csv‚Äù in the data folder:\n\nexport(x = life_expectancy, file = \"data/test_data_export.csv\")"
  },
  {
    "objectID": "task1.html",
    "href": "task1.html",
    "title": "Task 1: Setting up an automated report",
    "section": "",
    "text": "This task introduces Quarto, a document type for generating automated reports (and websites and presentations) that interface with R. You will learn how to create reproducible reports that can be easily updated as new data becomes available, enabling efficient and consistent epidemiological reporting workflows."
  },
  {
    "objectID": "task1.html#overview",
    "href": "task1.html#overview",
    "title": "Task 1: Setting up an automated report",
    "section": "",
    "text": "This task introduces Quarto, a document type for generating automated reports (and websites and presentations) that interface with R. You will learn how to create reproducible reports that can be easily updated as new data becomes available, enabling efficient and consistent epidemiological reporting workflows."
  },
  {
    "objectID": "task1.html#setting-up-your-quarto-document",
    "href": "task1.html#setting-up-your-quarto-document",
    "title": "Task 1: Setting up an automated report",
    "section": "Setting Up Your Quarto Document",
    "text": "Setting Up Your Quarto Document\nNow let‚Äôs create a basic Quarto document that you‚Äôll use for your epidemiological reports.\n\nStep 1: Create a New Quarto Document\n\nIn RStudio, go to File ‚Üí New File ‚Üí Quarto Document.\nChoose HTML as the output format.\nGive your document a title (e.g., ‚ÄúEpidemiological Situation Report‚Äù).\nClick Create.\nSave the document in your project folder (e.g., sitrep.qmd).\n\n\nUnderstanding Visual and Source Editing Modes\nWhen you open your Quarto document, you‚Äôll notice two editing mode buttons in the top-left corner of the editor: Visual and Source.\n\nVisual mode: Provides a ‚ÄúWhat You See Is What You Get‚Äù editing experience, similar to a word processor. You can format text using buttons and menus, and see a preview of how your document will look.\nSource mode: Shows the raw Markdown and code syntax. You work directly with the text, code chunks, and formatting syntax (like ## for headings, **bold** for bold text, etc.).\n\nFor the rest of this tutorial and the task tutorials, we‚Äôll assume you‚Äôre using Source mode. This allows you to directly copy and paste code chunks and content from the tutorials into your document. You can switch between modes at any time using the buttons in the top-left corner - just click Source to switch to source mode.\n\n\n\nStep 2: Set Up the YAML Header and Report Structure\nAt the top of your Quarto document, you‚Äôll see a YAML header (the section between the --- lines). The YAML header contains metadata about your document, such as the title and output format. It tells Quarto how to render your document.\nEnsure your YAML header looks like this:\n---\ntitle: \"Epidemiological Situation Report\"\nformat: html\neditor: visual\n---\nBelow the YAML header, create a basic report structure with sections. In Quarto (and Markdown), you use ## to create section headings (level 2 headings). Each ## creates a new major section in your report. You can use ### for subsections, #### for sub-subsections, and so on.\nAdd this basic outline to your document:\n## Overview\n\nThis section will provide an introduction and overview of the situation report.\n\n## Epidemiological Trends\n\nThis section will describe epidemiological trends.\n\n## Severity\n\nThis section will conduct a severity analysis.\n\n## Conclusions\n\nThis section will summarize findings and next steps.\n\nUnderstanding Code Chunks\nA code chunk is a section in your Quarto document where you write and execute R code. Code chunks are enclosed between three backticks (```) followed by {r} and closed with three more backticks.\nTo create a code chunk:\n\nType three backticks followed by {r} on a new line: ```{r}\nPress Enter to start a new line\nWrite your R code\nType three backticks on a new line to close the chunk: ```\n\nHere‚Äôs what a code chunk looks like:\n```{r}\n# Your R code goes here\nlibrary(tidyverse)\n```\nYou can also insert a code chunk in RStudio by:\n\nClicking the Insert button (green plus icon with a ‚ÄúC‚Äù) in the toolbar, or\nUsing the keyboard shortcut: Ctrl+Alt+I (Windows/Linux) or Cmd+Option+I (Mac)\n\nCode chunks allow you to run R code, create plots, generate tables, and perform data analysis. The results (outputs, plots, tables) will appear in your rendered HTML report.\n\n\n\nStep 3: Install and Load Basic Packages\nIn the first code chunk of your document, install and load the basic packages needed for report generation. We‚Äôll use pacman, a package management tool for R that simplifies installing and loading packages. Pacman automatically installs packages if they‚Äôre not already installed, then loads them - making it much easier to manage dependencies.\n\n\nCode\n# Install pacman if needed\nif (!requireNamespace(\"pacman\", quietly = TRUE)) {\n  install.packages(\"pacman\")\n}\n\n# Install and load required packages using pacman\npacman::p_load(\n  tidyverse,  # For data manipulation and visualization\n  rio,        # For importing data\n  reactable   # For interactive tables\n)\n\n\nNote: We‚Äôll add more packages as needed when you work through specific tasks. Additional packages will be installed as you progress through the tutorials.\n\n\nStep 4: Render Your Report\nNow let‚Äôs test that everything is working by rendering your report:\n\nClick the Render button in RStudio (or press Ctrl+Shift+K / Cmd+Shift+K).\nQuarto will process your document and generate an HTML file.\nThe HTML report will open automatically in your browser.\n\nYou should now see a basic HTML report with your title and section headings. This confirms that your Quarto setup is working correctly!\nIf you prefer, you can download the example sitrep template directly instead of creating it yourself:\nDownload solution file"
  },
  {
    "objectID": "task1.html#additional-resources",
    "href": "task1.html#additional-resources",
    "title": "Task 1: Setting up an automated report",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nQuarto Tutorial: An overview of the basics, including rendering, authoring, YAML headers, code chunks and markdown text.\nQuarto Guide: A comprehensive guide covering all aspects of Quarto, including authoring, computations, tools, documents, presentations, dashboards, websites and more."
  },
  {
    "objectID": "task2.html",
    "href": "task2.html",
    "title": "Task 2: Basic descriptive analyses",
    "section": "",
    "text": "This task covers basic descriptive analyses for epidemiological data. You will learn how to generate summary statistics, create incidence curves, visualize demographic patterns, and build foundational components of an epidemiological situation report."
  },
  {
    "objectID": "task2.html#overview",
    "href": "task2.html#overview",
    "title": "Task 2: Basic descriptive analyses",
    "section": "",
    "text": "This task covers basic descriptive analyses for epidemiological data. You will learn how to generate summary statistics, create incidence curves, visualize demographic patterns, and build foundational components of an epidemiological situation report."
  },
  {
    "objectID": "task2.html#learning-objectives",
    "href": "task2.html#learning-objectives",
    "title": "Task 2: Basic descriptive analyses",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCreate automated report generation workflows\nIncorporate dynamic figures and tables\nUse Quarto for report generation\nBuild a basic epidemiological report with incidence curves and summary statistics\nVisualize demographic patterns using age-sex pyramids"
  },
  {
    "objectID": "task2.html#tutorial",
    "href": "task2.html#tutorial",
    "title": "Task 2: Basic descriptive analyses",
    "section": "Tutorial",
    "text": "Tutorial\nFor detailed guidance on creating and customizing visualizations:\n\nEpidemic Curves tutorial - Learn how to create and customize incidence curves\nDemographic Pyramids tutorial - Learn how to create age-sex pyramids"
  },
  {
    "objectID": "task2.html#example-report",
    "href": "task2.html#example-report",
    "title": "Task 2: Basic descriptive analyses",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\n\nCode\n# INSTALL AND LOAD PACKAGES\n\n# Load required packages\npacman::p_load(\n  tidyverse, # For data manipulation and visualization\n  reactable, # For interactive tables\n  lubridate, # For date handling\n  apyramid # For age-sex pyramids\n)\n\n\n# LOAD DATA\n\n# Import the cleaned linelist data from your local data folder\nlinelist &lt;- readRDS(\"data/linelist.rds\")\n\n\n# SUMMARY STATISTICS\n\n# Calculate first case month and peak month\nfirst_case &lt;- which.min(linelist$date_onset)\nfirst_case_location &lt;- paste0(linelist$adm3[first_case], \", \", linelist$adm2[first_case])\nfirst_case_month &lt;- format(linelist$date_onset[first_case], \"%B %Y\")\n\n# Calculate month with most cases\nmonthly_cases &lt;- linelist |&gt;\n  filter(!is.na(date_onset)) |&gt;\n  mutate(month = floor_date(date_onset, unit = \"month\")) |&gt;\n  count(month) |&gt;\n  arrange(desc(n))\n\n# Extract monthly information\npeak_month &lt;- format(monthly_cases$month[1], \"%B %Y\")\npeak_cases &lt;- monthly_cases$n[1]\n\n# Create summary table by adm3\nadm3_summary &lt;- linelist |&gt;\n  summarise(\n    total_cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm = TRUE),\n    .by = adm3\n  ) |&gt;\n  arrange(desc(total_cases))\n\n\n\nOverview\nThe first case was reported in Mountain Rural, Western Area Rural on April 2014. Case numbers increased to a maximum of 1112 cases in October 2014 before declining.\n\n\nCode\n# CREATE INCIDENCE CURVE\n\n# Create incidence curve\nincidence_curve &lt;- linelist |&gt;\n  ggplot(aes(x = date_onset, fill = adm3)) +\n  geom_histogram(binwidth = 7) +\n  scale_fill_viridis_d(\n    guide = guide_legend(reverse = FALSE),\n    na.value = \"grey\"\n  ) +\n  labs(\n    x = \"Date of Onset\",\n    y = \"Number of Cases\",\n    fill = \"Chiefdom\"\n  ) +\n  theme_minimal()\n\n# Display the plot\nincidence_curve\n\n\n\n\n\n\n\n\n\nSummary statistics of case and deaths by chiefdom are provided below.\n\n\nCode\n# Create interactive table\nreactable(\n  adm3_summary,\n  columns = list(\n    adm3 = colDef(name = \"Chiefdom\"),\n    total_cases = colDef(name = \"Total Cases\"),\n    deaths = colDef(name = \"Deaths\")\n  ),\n  defaultPageSize = nrow(adm3_summary)\n)\n\n\n\n\n\n\n\n\nAge and Sex Distribution\nThe age and sex distribution of cases was visualized to identify demographic patterns in the outbreak.\n\n\nCode\n# CREATE AGE-SEX PYRAMID\n\n# Create age-sex pyramid using apyramid package\nage_pyramid &lt;- apyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat\",\n  split_by = \"gender\",\n  show_midpoint = FALSE\n) +\n  labs(\n    title = NULL,\n    x = \"Age Group\",\n    y = \"Number of Cases\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\"\n  )\n\n# Display the plot\nage_pyramid\n\n\n\n\n\n\n\n\n\n\n\nDisease Severity\n\n\nCode\n# Calculate CFR (excluding NA outcomes)\ncfr &lt;- linelist |&gt;\n  filter(!is.na(outcome)) |&gt;\n  summarise(\n    total_cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm = TRUE),\n    recovered = sum(outcome == \"Recover\", na.rm = TRUE),\n    unknown = sum(is.na(outcome)),\n    cfr = round((deaths / (deaths + recovered)) * 100, 0)\n  )\n\nmissing_outcome &lt;- scales::percent(mean(is.na(linelist$outcome)))\n\n\nThe crude case fatality ratio (CFR) was estimated at 57%, though the outcome was unknown for 22% of cases. CFR estimates were also generated by health facility to identify potential facilities with significantly worse outcomes. You will learn to calculate CFR more robustly in Task 6 using the cfr package.\n\n\nCode\n# Create summary table by hospital\nhospital_summary &lt;- linelist |&gt;\n  # group missing and other hospitals\n  mutate(\n    hospital = modify_if(hospital, ~ .x %in% c(\"Other\", \"Missing\"), ~\"Other/Missing\")\n  ) |&gt;\n  summarise(\n    total_cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm = TRUE),\n    recovered = sum(outcome == \"Recover\", na.rm = TRUE),\n    unknown = sum(is.na(outcome)),\n    cfr = round((deaths / (deaths + recovered)) * 100, 0),\n    .by = hospital\n  )\n\n# Create interactive table\nreactable(\n  hospital_summary,\n  columns = list(\n    hospital = colDef(name = \"Hospital\"),\n    total_cases = colDef(name = \"Total Cases\"),\n    deaths = colDef(name = \"Deaths\"),\n    recovered = colDef(name = \"Recovered\"),\n    unknown = colDef(name = \"Unknown\"),\n    cfr = colDef(name = \"CFR (%)\")\n  ),\n  defaultPageSize = nrow(hospital_summary)\n)"
  },
  {
    "objectID": "task4.html",
    "href": "task4.html",
    "title": "Task 4: Visualising transmission chains",
    "section": "",
    "text": "This task covers visualizing transmission chains using epicontacts. You will learn how to analyze and visualize contact networks and transmission pathways."
  },
  {
    "objectID": "task4.html#overview",
    "href": "task4.html#overview",
    "title": "Task 4: Visualising transmission chains",
    "section": "",
    "text": "This task covers visualizing transmission chains using epicontacts. You will learn how to analyze and visualize contact networks and transmission pathways."
  },
  {
    "objectID": "task4.html#learning-objectives",
    "href": "task4.html#learning-objectives",
    "title": "Task 4: Visualising transmission chains",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nWork with contact network data\nVisualize transmission chains using epicontacts\nAnalyze contact patterns\nIdentify transmission clusters"
  },
  {
    "objectID": "task4.html#tutorial",
    "href": "task4.html#tutorial",
    "title": "Task 4: Visualising transmission chains",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task4.html#example-report",
    "href": "task4.html#example-report",
    "title": "Task 4: Visualising transmission chains",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file\n\n\nCode\n# INSTALL AND LOAD PACKAGES\n\n# install development version of epicontacts\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# Load required packages\npacman::p_load(\n  rio, # File import\n  here, # File locator\n  tidyverse, # Data management + ggplot2 graphics\n  remotes, # Package installation from github\n  epicontacts, # Transmission chain analysis\n  reactable # Interactive tables\n)\n\n\n# LOAD DATA\n# Import the cleaned linelist data\nlinelist &lt;- readRDS(\"data/linelist.rds\")\n\n\n# SETTING UP EPICONTACTS\n\n## generate contacts\ncontacts &lt;- linelist |&gt;\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    source = source\n  ) |&gt;\n  drop_na(infector)\n\n# generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\n\n\nFuneral infections\nWe first investigated funeral infections that occured during the year of 2014. Hover individual cases to get more detailed information.\n\n\nCode\n# filter by nosocomial infection between april and july\nfuneral &lt;- subset(\n  epic,\n  node_attribute = list(\n    date_infection = as.Date(c(\"2014-01-01\", \"2014-12-31\"))\n  ),\n  edge_attribute = list(source = \"funeral\")\n) |&gt;\n  thin(what = \"contacts\") |&gt;\n  thin(what = \"linelist\")\n\n# plot and set the selector to hospital\nplot(\n  funeral,\n  label = FALSE,\n  node_color = \"gender\",\n  selector = \"adm3\",\n  height = 400,\n  width = 600\n)\n\n\n\n\n\n\n\n\nInfection clusters\n\n\nCode\n# add cluster information\nclusters &lt;- get_clusters(epic)\nlargest_cluster &lt;- which.max(clusters$linelist$cluster_size)\nlargest_size &lt;- clusters$linelist$cluster_size[largest_cluster]\nlargest &lt;- subset(epic, cluster_id = clusters$linelist$id[largest_cluster])\n\n\nThe largest transmission cluster consisted of 14 cases and is depicted on a timeline below.\n\n\nCode\n# plot\nplot(\n  largest,\n  node_color = \"gender\",\n  selector = \"hospital\",\n  x_axis = \"date_infection\",\n  date_labels = \"%d %b %Y\",\n  label = FALSE,\n  height = 400,\n  width = 600,\n  node_size = 8,\n  arrow_size = 0.25,\n  network_shape = \"rectangle\"\n)"
  },
  {
    "objectID": "task6.html",
    "href": "task6.html",
    "title": "Task 6: Estimating disease severity",
    "section": "",
    "text": "This task focuses on estimating disease severity. You will learn how to calculate and interpret key severity metrics such as case fatality ratio and infection fatality ratio."
  },
  {
    "objectID": "task6.html#overview",
    "href": "task6.html#overview",
    "title": "Task 6: Estimating disease severity",
    "section": "",
    "text": "This task focuses on estimating disease severity. You will learn how to calculate and interpret key severity metrics such as case fatality ratio and infection fatality ratio."
  },
  {
    "objectID": "task6.html#learning-objectives",
    "href": "task6.html#learning-objectives",
    "title": "Task 6: Estimating disease severity",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate case fatality ratio (CFR)\nEstimate infection fatality ratio (IFR)\nAdjust for time-to-death and censoring\nCompare severity across populations and time periods"
  },
  {
    "objectID": "task6.html#tutorial",
    "href": "task6.html#tutorial",
    "title": "Task 6: Estimating disease severity",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task6.html#example-report",
    "href": "task6.html#example-report",
    "title": "Task 6: Estimating disease severity",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file"
  },
  {
    "objectID": "task6.html#estimating-case-fatality-risk-cfr-in-real-time",
    "href": "task6.html#estimating-case-fatality-risk-cfr-in-real-time",
    "title": "Task 6: Estimating disease severity",
    "section": "Estimating Case Fatality Risk (CFR) in real-time",
    "text": "Estimating Case Fatality Risk (CFR) in real-time\nTo estimate the static CFR at a specific time-point during the outbreak, we subset the data to include the initial 150 days of the outbreak only. Then we estimate both the naive and the delay-adjusted CFR.\n\n\nCode\n# Prepare data for {cfr} package\nebola_data_cfr &lt;- ebola_cases_deaths %&gt;%\n  pivot_wider(names_from = count_variable, values_from = count) %&gt;%\n  rename(cases = date_onset, deaths = date_death)\n\nebola_rt &lt;- ebola_data_cfr %&gt;%\n  slice(1:150)\n\n# Naive CFR\ncfr_naive &lt;- cfr::cfr_static(data = ebola_rt)\n\n# Delay-adjusted CFR\n# Getting distribution from {epiparameter}\nonset_to_death_ebola &lt;-\n  epiparameter::epiparameter_db(\n    disease = \"Ebola\",\n    epi_name = \"onset_to_death\",\n    single_epiparameter = TRUE\n  )\n\ncfr_adjusted &lt;- cfr::cfr_static(data = ebola_rt, delay_density = function(x) density(onset_to_death_ebola, x))\n\n# Create table with CFR estimates and confidence intervals\n# Create table with CFR estimates and confidence intervals\ncfr_table &lt;- tibble(\n  Method = c(\"Naive CFR\", \"Adjusted CFR\"),\n  Estimate = c(\n    round(cfr_naive$severity_estimate, 2),\n    round(cfr_adjusted$severity_estimate, 2)\n  ),\n  `Lower CI` = c(\n    round(cfr_naive$severity_low, 2),\n    round(cfr_adjusted$severity_low, 2)\n  ),\n  `Upper CI` = c(\n    round(cfr_naive$severity_high, 2),\n    round(cfr_adjusted$severity_high, 2)\n  )\n)\n\nreactable(\n  cfr_table,\n  columns = list(\n    Method = colDef(name = \"Method\"),\n    Estimate = colDef(name = \"Estimate\")\n  ),\n  fullWidth = FALSE\n)\n\n\n\n\n\n\nThe naive CFR underestimates the case fatality risk by 7%."
  },
  {
    "objectID": "task8.html",
    "href": "task8.html",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "",
    "text": "This task walks you through nowcasting epidemiological data. You will learn to correct for epidemiological and reporting delays so you can estimate current case counts even when the data are incomplete. Along the way, you will learn how to work with the delay distributions provided by {epiparameter}‚Äîdiscretising continuous distributions, turning parameters into {EpiNow2} inputs, and using those distribution functions to guide decisions like setting appropriate quarantine lengths."
  },
  {
    "objectID": "task8.html#overview",
    "href": "task8.html#overview",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "",
    "text": "This task walks you through nowcasting epidemiological data. You will learn to correct for epidemiological and reporting delays so you can estimate current case counts even when the data are incomplete. Along the way, you will learn how to work with the delay distributions provided by {epiparameter}‚Äîdiscretising continuous distributions, turning parameters into {EpiNow2} inputs, and using those distribution functions to guide decisions like setting appropriate quarantine lengths."
  },
  {
    "objectID": "task8.html#learning-objectives",
    "href": "task8.html#learning-objectives",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand reporting delays and their impact\nApply nowcasting methods to epidemiological data\nAdjust for underreporting and delays\nGenerate real-time estimates of current incidence"
  },
  {
    "objectID": "task8.html#tutorial",
    "href": "task8.html#tutorial",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "Tutorial",
    "text": "Tutorial\nAccess the tutorial here"
  },
  {
    "objectID": "task8.html#downloading-nowcast-estimates",
    "href": "task8.html#downloading-nowcast-estimates",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "Downloading Nowcast Estimates",
    "text": "Downloading Nowcast Estimates\nNote: Running EpiNow2 can be computationally expensive and may take several minutes to complete. If you want to skip this step, you can download the pre-computed estimates file and place it in your outputs/ folder:\nDownload nowcast estimates"
  },
  {
    "objectID": "task8.html#example-report",
    "href": "task8.html#example-report",
    "title": "Task 8: Nowcasting epidemiological data",
    "section": "Example Report",
    "text": "Example Report\nDownload solution file solution file\n\nVisualising available epiparameter distributions\nWe first explore the available distributions in {epiparameter} that we can use to adjust for delays during an Ebola outbreak.\n\n\nCode\n# INSTALL AND LOAD PACKAGES\npacman::p_load(tidyverse, EpiNow2, incidence2, reactable, rio)\n\n# List distributions\nepiparameter::epiparameter_db(disease = \"ebola\") |&gt;\n  epiparameter::parameter_tbl() |&gt;\n  select(-disease) |&gt;\n  reactable::reactable(defaultPageSize = 5)\n\n\n\n\n\n\n\n\nExtracting relevant parameters and adjusting for delays\nWe imported linelist data for the Ebola outbreak, and converted it to incidence. Then extracted parameter distributions for the serial interval and incubation period for Ebola, chosen from the table above.\n\n\nCode\n# LOAD DATA\n# Import linelist data and convert to incidence\nebola_incidence &lt;- readRDS(\"data/linelist.rds\") |&gt;\n  incidence2::incidence(\n    date_index = \"date_onset\",\n    count_values_to = \"confirm\",\n    date_names_to = \"date\",\n    complete_dates = TRUE\n  ) |&gt;\n  dplyr::select(-count_variable)\n\n# serial interval ---------------------------------------------------------\n\n# subset one distribution for the SI\nebola_serial &lt;- epiparameter::epiparameter_db(\n  disease = \"ebola\",\n  epi_name = \"serial\",\n  single_epiparameter = TRUE\n)\n\n# adapt SI epiparameter object to EpiNow2\nebola_serial_discrete &lt;- epiparameter::discretise(ebola_serial)\n\nserial_interval_ebola &lt;-\n  EpiNow2::Gamma(\n    mean = ebola_serial$summary_stats$mean,\n    sd = ebola_serial$summary_stats$sd,\n    max = quantile(ebola_serial_discrete, p = 0.99)\n  )\n\n# incubation period ---------------------------------------------------------\n\n# subset one distribution for ebola incubation period\nebola_incubation &lt;- epiparameter::epiparameter_db(\n  disease = \"ebola\",\n  epi_name = \"incubation\",\n  single_epiparameter = TRUE\n)\n\n# adapt IP epiparameter object to EpiNow2\nebola_incubation_discrete &lt;- epiparameter::discretise(ebola_incubation)\n\nincubation_period_ebola &lt;-\n  EpiNow2::Gamma(\n    mean = ebola_incubation$summary_stats$mean,\n    sd = ebola_incubation$summary_stats$sd,\n    max = quantile(ebola_serial_discrete, p = 0.99)\n  )\n\n# reporting delay ---------------------------------------------------------\nreporting_delay &lt;- EpiNow2::LogNormal(\n  mean = 10,\n  sd = 3,\n  max = 15\n)\n\n# check if the analysis has been run before and run EpiNow2 if not\nfile_name &lt;- \"outputs/nowcast_estimates.rds\"\nif (file.exists(file_name)) {\n  nowcast_estimates &lt;- import(file_name)\n} else {\n  # nowcasting with epinow ---------------------------------------------------\n  withr::local_options(base::list(mc.cores = 4))\n  nowcast_estimates &lt;- EpiNow2::estimate_infections(\n    data = ebola_incidence,\n    generation_time = EpiNow2::generation_time_opts(serial_interval_ebola),\n    delays = EpiNow2::delay_opts(incubation_period_ebola + reporting_delay),\n    forecast = NULL,\n    stan = EpiNow2::stan_opts(samples = 500, chains = 2)\n  )\n  export(nowcast_estimates, file_name)\n}\n\n\nWe then adjust for a reporting delay of 10 days from onset to notification, on average.\n\n\nCode\ninfection_plot &lt;- plot(nowcast_estimates, type = \"infections\")\n\nweekly_obs &lt;- nowcast_estimates$observations %&gt;%\n  mutate(week= floor_date(date, \"week\", week_start = 1)) %&gt;%\n  group_by(week) %&gt;%\n  summarise(\n    confirm = mean(confirm, na.rm = TRUE),  # average daily cases that week\n    .groups = \"drop\"\n  )\n\ninfection_plot$layers &lt;- infection_plot$layers[-1]\n\ninfection_plot +\n  geom_col(\n    data = weekly_obs,\n    aes(x = week, y = confirm),\n    inherit.aes = FALSE,\n    fill = \"#9ca3af\",\n    alpha = 0.4,\n    width = 6\n  )"
  }
]